"use strict";(self.webpackChunkstarlake_docs=self.webpackChunkstarlake_docs||[]).push([[6261],{3905:function(e,t,n){n.d(t,{Zo:function(){return u},kt:function(){return E}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=a.createContext({}),s=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},u=function(e){var t=s(e.components);return a.createElement(c.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,c=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),m=s(n),E=r,T=m["".concat(c,".").concat(E)]||m[E]||p[E]||o;return n?a.createElement(T,l(l({ref:t},u),{},{components:n})):a.createElement(T,l({ref:t},u))}));function E(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,l=new Array(o);l[0]=m;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i.mdxType="string"==typeof e?e:r,l[1]=i;for(var s=2;s<o;s++)l[s]=n[s];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},3025:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return i},metadata:function(){return c},toc:function(){return s},default:function(){return p}});var a=n(7462),r=n(3366),o=(n(7294),n(3905)),l={sidebar_position:1},i="Extract",c={unversionedId:"howto/extract",id:"howto/extract",isDocsHomePage:!1,title:"Extract",description:"This feature allows you to extract files from any JDBC compliant database to comma delimited values files.",source:"@site/docs/howto/extract.md",sourceDirName:"howto",slug:"/howto/extract",permalink:"/starlake/docs/howto/extract",editUrl:"https://github.com/starlake-ai/starlake/edit/master/docs/docs/howto/extract.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"cometSidebar",previous:{title:"Transform",permalink:"/starlake/docs/reference/transform"},next:{title:"Load",permalink:"/starlake/docs/howto/load"}},s=[{value:"The YAML File",id:"the-yaml-file",children:[]},{value:"The Mustache Template",id:"the-mustache-template",children:[]},{value:"The comet extract command",id:"the-comet-extract-command",children:[]}],u={toc:s};function p(e){var t=e.components,n=(0,r.Z)(e,["components"]);return(0,o.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"extract"},"Extract"),(0,o.kt)("p",null,"This feature allows you to extract files from any JDBC compliant database to comma delimited values files."),(0,o.kt)("p",null,"To extract a table of view content, we need to :"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Write a YAML file that describe the table schema or generate this YAML file using the extraction script."),(0,o.kt)("li",{parentName:"ul"},"a mustache template that describe how the table data should be extracted as files. A generic mustache template is provided below"),(0,o.kt)("li",{parentName:"ul"},"Run ",(0,o.kt)("inlineCode",{parentName:"li"},"comet extract")," to apply the templated script to your database")),(0,o.kt)("h2",{id:"the-yaml-file"},"The YAML File"),(0,o.kt)("p",null,"The extract and load process are both based on the same YAML description file.\nPlease check first how a schema is described in ",(0,o.kt)("a",{parentName:"p",href:"/starlake/docs/howto/load"},"How to load")),(0,o.kt)("p",null,"The only difference is that the YAML file for the extraction process describe a table schema instead of a formatted file schema.\nIn that case, the following YAML fields have a special meaning:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Domain Name : Database schema"),(0,o.kt)("li",{parentName:"ul"},"Schema Name : Table name")),(0,o.kt)("h2",{id:"the-mustache-template"},"The Mustache Template"),(0,o.kt)("p",null,"Write a mustache template that run a SQL export request to the target file.\nThe following parameters are available :"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"full_export : Boolean. If true means that we are requesting a full export"),(0,o.kt)("li",{parentName:"ul"},"export_file : filename of the exported data"),(0,o.kt)("li",{parentName:"ul"},"table_name : table name in uppercase"),(0,o.kt)("li",{parentName:"ul"},"delimiter : delimiter to use in the export file"),(0,o.kt)("li",{parentName:"ul"},"columns : Column map with the single name attribute")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"    -- How the data should be exported\n    SET ECHO OFF\n    SET VERIFY OFF\n    SET TRIMSPOOL ON\n    SET TRIMOUT ON\n    SET LINESIZE 9999\n    SET PAGESIZE 0\n    -- We decide to export without any header.\n    -- Do not forget to value the withHeader property to false in the YAML file\n    SET HEADING OFF\n    SET FEEDBACK OFF\n    SET TIMING OFF\n    SET TIME OFF\n    SET LONG 10000\n    -- The separator here should be the one used in the YAML file\n    SET COLSEP ';'\n    SET HEADSEP off\n\n    -- Stop in case of failure\n    WHENEVER SQLERROR exit 1;\n\n    -- Data time pattern we want to use\n    ALTER SESSION SET NLS_DATE_FORMAT = 'yyyymmddhh24miss';\n\n    -- The output file directory\n    DEFINE OUTPUT_DIR = &1;\n\n    -- Get current date/time.\n    COLUMN DT_VAL NEW_VALUE CURRENT_EXPORT_DATE_CHAR;\n    SELECT TO_CHAR(SYSDATE) DT_VAL FROM DUAL;\n\n    -- We store in a dedicated table, the last export date/time.\n    -- Useful for incremental exports\n    COLUMN LED NEW_VALUE LAST_EXPORT_DATE;\n    SELECT\n        COALESCE(\n            (\n                SELECT\n                    MAX(DA_LAST_EXPORT_DATE)\n                FROM\n                    MY_SCHEMA.COMET_EXPORT_STATUS\n                WHERE\n                    LI_SCHEMA_NAME = 'MY_SCHEMA' AND\n                    LI_TABLE_NAME = '{{table_name}}'\n            ),\n            TO_DATE('19700101','yyyymmdd') -- If table has never been exported\n        ) LED\n    FROM\n        DUAL;\n\n    -- Start export\n    PROMPT EXPORTING {{table_name}} TO &OUTPUT_DIR/{{export_file}}_{{#full_export}}FULL{{/full_export}}{{^full_export}}DELTA{{/full_export}}_&CURRENT_EXPORT_DATE_CHAR\\.csv;\n    SPOOL &OUTPUT_DIR/{{export_file}}_{{#full_export}}FULL{{/full_export}}{{^full_export}}DELTA{{/full_export}}_&CURRENT_EXPORT_DATE_CHAR\\.csv REPLACE\n\n    ALTER SESSION SET NLS_DATE_FORMAT = 'yyyy-mm-dd hh24:mi:ss';\n\n    -- SQL to execute if an incremental export is requested\n    {{^full_export}}\n    SELECT\n        {{#columns}}\n        TO_CHAR({{name}}) || ';' ||\n        {{/columns}}\n        ''\n    FROM\n        MY_SCHEMA.{{table_name}}\n    WHERE\n        {{delta_column}} >= '&LAST_EXPORT_DATE' AND {{delta_column}} IS NOT NULL;\n    {{/full_export}}\n\n    -- SQL to execute if a full export is requested\n    {{#full_export}}\n    SELECT\n        {{#columns}}\n        TO_CHAR({{name}}) || ';' ||\n        {{/columns}}\n        ''\n    FROM\n        MY_SCHEMA.{{table_name}};\n    {{/full_export}}\n\n    -- Export finished successfully\n    SPOOL OFF\n\n    -- Update reporot table containing the last expoort date\n    -- This is useful for audit purpose and for incremental export since we store the last export date here.\n    BEGIN\n        INSERT INTO\n            MY_SCHEMA.COMET_EXPORT_STATUS (LI_SCHEMA_NAME, LI_TABLE_NAME, DA_LAST_EXPORT_DATE, TYPE_LAST_EXPORT, NB_ROWS_LAST_EXPORT)\n        VALUES\n            (\n                'MY_SCHEMA',\n                '{{table_name}}',\n                TO_DATE(&CURRENT_EXPORT_DATE_CHAR),\n                {{#full_export}}\n                'FULL',\n                (\n                    SELECT\n                        COUNT(*)\n                    FROM\n                        MY_SCHEMA.{{table_name}}\n                )\n                {{/full_export}}\n                {{^full_export}}\n                'DELTA',\n                (\n                    SELECT\n                        COUNT(*)\n                    FROM\n                        MY_SCHEMA.{{table_name}}\n                    WHERE\n                        {{delta_column}} >= '&LAST_EXPORT_DATE' AND {{delta_column}} IS NOT NULL\n                )\n                {{/full_export}}\n            );\n    END;\n    /\n\n    EXIT SUCCESS\n\n    sqlplus sys/Ora_db1 as SYSDBA @ EXTRACT_{{table_name}}.sql /opt/oracle/user-scripts/scripts/\n")),(0,o.kt)("h2",{id:"the-comet-extract-command"},"The comet extract command"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"/starlake/docs/cli/import"},"CLI")))}p.isMDXComponent=!0}}]);