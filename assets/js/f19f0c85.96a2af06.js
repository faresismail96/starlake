"use strict";(self.webpackChunkstarlake_docs=self.webpackChunkstarlake_docs||[]).push([[6863],{3905:function(e,n,t){t.d(n,{Zo:function(){return m},kt:function(){return c}});var a=t(7294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var d=a.createContext({}),l=function(e){var n=a.useContext(d),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},m=function(e){var n=l(e.components);return a.createElement(d.Provider,{value:n},e.children)},p={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},u=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,d=e.parentName,m=o(e,["components","mdxType","originalType","parentName"]),u=l(t),c=r,y=u["".concat(d,".").concat(c)]||u[c]||p[c]||i;return t?a.createElement(y,s(s({ref:n},m),{},{components:t})):a.createElement(y,s({ref:n},m))}));function c(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var i=t.length,s=new Array(i);s[0]=u;var o={};for(var d in n)hasOwnProperty.call(n,d)&&(o[d]=n[d]);o.originalType=e,o.mdxType="string"==typeof e?e:r,s[1]=o;for(var l=2;l<i;l++)s[l]=t[l];return a.createElement.apply(null,s)}return a.createElement.apply(null,t)}u.displayName="MDXCreateElement"},4266:function(e,n,t){t.r(n),t.d(n,{frontMatter:function(){return s},contentTitle:function(){return o},metadata:function(){return d},toc:function(){return l},default:function(){return p}});var a=t(7462),r=t(3366),i=(t(7294),t(3905)),s={sidebar_position:2,title:"Load"},o=void 0,d={unversionedId:"examples/load",id:"examples/load",isDocsHomePage:!1,title:"Load",description:"This section describes how to import text files (eq. json / CSV) files into your Data Factory.",source:"@site/docs/examples/load.md",sourceDirName:"examples",slug:"/examples/load",permalink:"/starlake/docs/examples/load",editUrl:"https://github.com/starlake-ai/starlake/edit/master/docs/docs/examples/load.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,title:"Load"},sidebar:"cometSidebar",previous:{title:"Extract",permalink:"/starlake/docs/examples/extract"},next:{title:"Transform",permalink:"/starlake/docs/examples/transform"}},l=[{value:"Load to Parquet",id:"load-to-parquet",children:[]},{value:"Load to BigQuery",id:"load-to-bigquery",children:[]},{value:"Load to SQL Database",id:"load-to-sql-database",children:[]},{value:"Load to Elasticsearch",id:"load-to-elasticsearch",children:[{value:"Custom ES Template",id:"custom-es-template",children:[]}]}],m={toc:l};function p(e){var n=e.components,t=(0,r.Z)(e,["components"]);return(0,i.kt)("wrapper",(0,a.Z)({},m,t,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"This section describes how to import text files (eq. json / CSV) files into your Data Factory."),(0,i.kt)("h2",{id:"load-to-parquet"},"Load to Parquet"),(0,i.kt)("p",null,"Files will be ingested and stored in parquet format in the ",(0,i.kt)("inlineCode",{parentName:"p"},"$COMET_DATASETS/sales/customers")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"$COMET_DATASETS/sales/orders")," files."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'load:\n    name: "sales"\n    directory: "__COMET_TEST_ROOT__/incoming/sales"\n    metadata:\n      mode: "FILE"\n      format: "DSV"\n      withHeader: true\n      quote: "\\""\n      escape: "\\\\"\n      write: "APPEND"\n    schemas:\n      - name: "customers"\n        pattern: "customers-.*.psv"\n        metadata:\n          separator: "|"\n        attributes:\n          - name: "id"\n            type: "customerid"\n            required: true\n          - name: "signup"\n            type: "datetime"\n            required: false\n          - name: "contact"\n            type: "email"\n            required: false\n          - name: "birthdate"\n            type: "date"\n            required: false\n          - name: "name1"\n            type: "string"\n            required: false\n            rename: "firstname"\n          - name: "name2"\n            type: "string"\n            required: false\n            rename: "lastname"\n      - name: "orders"\n        pattern: "orders-.*.csv"\n        merge:\n          key:\n            - "id"\n          delete: "customer_id is null"\n        metadata:\n          separator: ","\n        attributes:\n          - name: "order_id"\n            type: "string"\n            required: true\n            rename: "id"\n          - name: "customer_id"\n            type: "customerid"\n            required: false\n          - name: "amount"\n            type: "decimal"\n            required: false\n          - name: "seller_id"\n            type: "string"\n            required: false\n')),(0,i.kt)("h2",{id:"load-to-bigquery"},"Load to BigQuery"),(0,i.kt)("p",null,"Based on the ",(0,i.kt)("a",{parentName:"p",href:"#load-to-parquet"},"Load to parquet")," example, the only thing we add is the /metadata/sink section\nFiles will be stored in the ",(0,i.kt)("inlineCode",{parentName:"p"},"customers")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"orders")," BigQuery tables under the ",(0,i.kt)("inlineCode",{parentName:"p"},"sales")," BigQuery dataset"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'load:\n    name: "sales"\n    directory: "/incoming/sales"\n    metadata:\n      mode: "FILE"\n      format: "DSV"\n      withHeader: true\n      quote: "\\""\n      escape: "\\\\"\n      write: "APPEND"\n      sink:\n        type: BQ\n    schemas:\n      - name: "customers"\n        pattern: "customers-.*.psv"\n        metadata:\n          separator: "|"\n        attributes:\n          - name: "id"\n            type: "customerid"\n            required: true\n          - name: "signup"\n            type: "datetime"\n            required: false\n          - name: "contact"\n            type: "email"\n            required: false\n          - name: "birthdate"\n            type: "date"\n            required: false\n          - name: "name1"\n            type: "string"\n            required: false\n            rename: "firstname"\n          - name: "name2"\n            type: "string"\n            required: false\n            rename: "lastname"\n      - name: "orders"\n        pattern: "orders-.*.csv"\n        merge:\n          key:\n            - "id"\n          delete: "customer_id is null"\n        metadata:\n          separator: ","\n        attributes:\n          - name: "order_id"\n            type: "string"\n            required: true\n            rename: "id"\n          - name: "customer_id"\n            type: "customerid"\n            required: false\n          - name: "amount"\n            type: "decimal"\n            required: false\n          - name: "seller_id"\n            type: "string"\n            required: false\n')),(0,i.kt)("h2",{id:"load-to-sql-database"},"Load to SQL Database"),(0,i.kt)("p",null,"Based on the ",(0,i.kt)("a",{parentName:"p",href:"#load-to-parquet"},"Load to parquet")," example, we need to"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"Add  the /metadata/sink section")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'load:\n    name: "hr"\n    directory: "/incoming/hr"\n    metadata:\n      mode: "FILE"\n      format: "JSON"\n      sink:\n        type: JDBC\n        connection: my_connection\n        partitions: 10\n        batchSize: 1000\n    schemas:\n      - name: "sellers"\n        pattern: "sellers-.*.json"\n        metadata:\n          array: true\n          format: "SIMPLE_JSON"\n          write: "APPEND"\n        attributes:\n          - name: "id"\n            type: "string"\n            required: true\n          - name: "seller_email"\n            type: "email"\n            required: true\n          - name: "location_id"\n            type: "long"\n            required: true\n      - name: "locations"\n        pattern: "locations-.*.json"\n        metadata:\n          format: "JSON"\n          write: "OVERWRITE"\n        attributes:\n          - name: "id"\n            type: "string"\n            required: true\n          - name: "address"\n            type: "struct"\n            required: true\n            attributes:\n              - name: "city"\n                type: "string"\n                required: true\n                metricType: "discrete"\n              - name: "stores"\n                type: "string"\n                array: true\n                required: false\n              - name: "country"\n                type: "string"\n                required: true\n                metricType: "discrete"\n')),(0,i.kt)("ol",{start:2},(0,i.kt)("li",{parentName:"ol"},"Add to the jdbc section a connection with the name specified in the /medata/sink/connection property")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-javascript"},'jdbc = {\n  "my_connection": {\n    uri = "jdbc:postgresql://127.0.0.1:5403/mydb?user=postgres&password=XXXX-XXXX-XXXX",\n    user = "postgres",\n    password = "XXXX-XXXX-XXXX",\n    driver = "org.postgresql.Driver"\n  }\n}\n')),(0,i.kt)("h2",{id:"load-to-elasticsearch"},"Load to Elasticsearch"),(0,i.kt)("p",null,"Based on the example ",(0,i.kt)("a",{parentName:"p",href:"#load-to-parquet"},"Load to parquet")," example, we add is the /metadata/sink section to both schemas."),(0,i.kt)("p",null,"For the sake of the example, we added a field to the location schema to highlight how timestamped indexes may be handled.\nIndexes will be named after the domain and schema names suffixed by the timestamp if present."),(0,i.kt)("p",null,"The ",(0,i.kt)("inlineCode",{parentName:"p"},"orders")," index will be named ",(0,i.kt)("inlineCode",{parentName:"p"},"sales_orders")," and the ",(0,i.kt)("inlineCode",{parentName:"p"},"customers")," index will have a name similar to ",(0,i.kt)("inlineCode",{parentName:"p"},"sales_customers-2020.01.31")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-yaml"},'load:\n    name: "sales"\n    directory: "__COMET_TEST_ROOT__/incoming/sales"\n    metadata:\n      mode: "FILE"\n      format: "DSV"\n      withHeader: true\n      quote: "\\""\n      escape: "\\\\"\n      write: "APPEND"\n      sink:\n        type: BQ\n    schemas:\n      - name: "customers"\n        pattern: "customers-.*.psv"\n        metadata:\n          separator: "|"\n          sink:\n            type: ES\n            timestamp: "{signup|yyyy.MM.dd}"\n        attributes:\n          - name: "id"\n            type: "customerid"\n            required: true\n          - name: "signup"\n            type: "datetime"\n            required: false\n          - name: "contact"\n            type: "email"\n            required: false\n          - name: "birthdate"\n            type: "date"\n            required: false\n          - name: "name1"\n            type: "string"\n            required: false\n            rename: "firstname"\n          - name: "name2"\n            type: "string"\n            required: false\n            rename: "lastname"\n      - name: "orders"\n        pattern: "orders-.*.csv"\n        merge:\n          key:\n            - "id"\n          delete: "customer_id is null"\n        metadata:\n          separator: ","\n          sink:\n            type: ES\n        attributes:\n          - name: "order_id"\n            type: "string"\n            required: true\n            rename: "id"\n          - name: "customer_id"\n            type: "customerid"\n            required: false\n          - name: "amount"\n            type: "decimal"\n            required: false\n          - name: "seller_id"\n            type: "string"\n            required: false\n')),(0,i.kt)("h3",{id:"custom-es-template"},"Custom ES Template"),(0,i.kt)("p",null,"By default, Comet will infer from the dataset schema the properties and their types and create the ES template accordingly.\nThe default template template is shown below. The variable  ",(0,i.kt)("inlineCode",{parentName:"p"},"__ATTRIBUTES__")," is substituted by the Comet with\nthe ES representation of the attributes."),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "index_patterns": ["{{domain}}.{{schema}}", "{{domain}}.{{schema}}-*"],\n  "settings": {\n    "number_of_shards": "1",\n    "number_of_replicas": "0"\n  },\n  "mappings": {\n    "_doc": {\n      "_source": {\n        "enabled": true\n      },\n      "properties": {\n        {{attributes}}\n      }\n    }\n  }\n}\n')),(0,i.kt)("p",null,"You may customize your ES template by creating a similar file with your own custom properties for a specific schema by putting it\nin the file with the following name ",(0,i.kt)("inlineCode",{parentName:"p"},"COMET_ROOT/metadata/mapping/${domainName}/${schemaName}.json"),"."),(0,i.kt)("p",null,"You may inject the domain and schema names using the ",(0,i.kt)("inlineCode",{parentName:"p"},"{{domain}}")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"{{schema}}")," substitution variables."))}p.isMDXComponent=!0}}]);